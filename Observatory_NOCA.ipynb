{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Watershed Dynamics Model: Get Gridded Climate Data <img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\" style=\"float:right;width:300px;padding:20px\">   \n",
    "\n",
    "Explore the North Cascades National Park from a HydroShare Observatory. <br />\n",
    "<br />\n",
    "Use this Jupyter Notebook to: <br /> \n",
    "Download daily 1/16 degree gridded climate data, <br /> \n",
    "Save climate data to a new HydroShare resource, <br /> \n",
    "Disaggreate daily data to 3-hourly, <br /> \n",
    "Estimate radiation and relative humidity from climate data, <br /> \n",
    "Visualize daily, monthly, and annual climate data. <br /> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developer Note - until these get installed on JupyterHub, open a new terminal and run the following commands on your local virtual machine: <br/>\n",
    "<br/>\n",
    " conda install ulmo  <br/>\n",
    " pip install ulmo  <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  HydroShare Setup and Preparation\n",
    "\n",
    "To run this notebook, we must import several libaries.\n",
    "The hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading and creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utilities import hydroshare, pypeline_scripts\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from geojson import Point, Feature, FeatureCollection\n",
    "# import mplleaflet\n",
    "\n",
    "import ulmo\n",
    "from ulmo.util import convert_datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to establish a secure connection with HydroShare. This is done by simply instantiating the hydroshare class that is defined within hs_utils. In addition to connecting with HydroShare, this command also sets and prints environment variables for several parameters that will be useful for saving your work back to HydroShare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the following system variables:\n",
      "   HS_USR_NAME = ChristinaBandaragoda\n",
      "   HS_RES_ID = bf5a8794894f44a19245582aed314a69\n",
      "   HS_RES_TYPE = genericresource\n",
      "   JUPYTER_HUB_IP = hydroroger.ncsa.illinois.edu\n",
      "\n",
      "These can be accessed using the following command: \n",
      "   os.environ[key]\n",
      "\n",
      "   (e.g.)\n",
      "   os.environ[\"HS_USR_NAME\"]  => ChristinaBandaragoda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:green;\">Successfully established a connection with HydroShare</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set variables for interacting with HydroShare from this notebook\n",
    "hs=hydroshare.hydroshare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/notebooks/data/bf5a8794894f44a19245582aed314a69/bf5a8794894f44a19245582aed314a69/data/contents/\n"
     ]
    }
   ],
   "source": [
    "# Create object to map the home directory\n",
    "homedir = r'/home/jovyan/work/notebooks/data/' + str(os.environ[\"HS_RES_ID\"]) + '/' + str(os.environ[\"HS_RES_ID\"]) + '/data/contents/'\n",
    "print homedir\n",
    "\n",
    "# if the working directory is not starting at homedir, set it to homedir\n",
    "if os.getcwd() != homedir:\n",
    "    os.chdir(homedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about where the data is being downloaded, click on the Jupyter Notebook dashboard icon to return to the File System view.  The homedir directory location printed above is where you can find the data and contents you will download to a HydroShare JupyterHub server.  At the end of this work session, you can migrate this data to the HydroShare iRods server as a Generic Resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get list of gridded climate points for the watershed\n",
    "Retrieve a list of grid points and configuration file from a HydroShare resource\n",
    "This example uses a ascii text that is stored in HydroShare at the following url: https://www.hydroshare.org/resource/d90289409f904017831d308642c1eb30/ . The data for our processing routines can be retrieved using the getResourceFromHydroShare function by passing in the global identifier from the url above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This resource already exists in your userspace.\n",
      "Would you like to overwrite this data [Y/n]? Y\n",
      "                       ...................................\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:green;\">Download Completed Successfully</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Found the following file(s) associated with this HydroShare resource.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "NOCA_280_Centroid_GriddedMet.csv"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "These files are stored in a dictionary called <b>hs.content</b> for your convenience.  To access a file, simply issue the following command where MY_FILE is one of the files listed above: <pre>hs.content[\"MY_FILE\"] </pre> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some resource content. The resource content is returned as a dictionary\n",
    "hs.getResourceFromHydroShare('bf5a8794894f44a19245582aed314a69')\n",
    "# Create object to map the mapping file directory\n",
    "\n",
    "#Geographic Raster -  generate Lat Long list of points within bounding box\n",
    "#hs.getResourceFromHydroShare('1a8e0a50990d4543adb5edc5219740d3')\n",
    "\n",
    "#Geographic Feature = generate Lat Long table from points within polygon with 5km buffer\n",
    "#hs.getResourceFromHydroShare('c532e0578e974201a0bc40a37ef2d284')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify the file containing lat/long points\n",
    "mappingfile = hs.content[\"NOCA_280_Centroid_GriddedMet.csv\"]\n",
    "#mappingfile = \"ElwhaClimatePoints_UTM_Elev.csv\"\n",
    "\n",
    "#Geographic Raster -  generate Lat Long list of points within bounding box\n",
    "#mappingfile = hs.content[\"SaukDEM_150m.tif\"]\n",
    "\n",
    "#Geographic Feature = generate Lat Long table from points within polygon with 5km buffer\n",
    "#mappingfile = hs.content[\"wbdhuc12_17110006.shp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check directory names and mapping file\n",
    "if 'homedir' not in globals():\n",
    "    print('homedir variable is missing')\n",
    "    sys.exit()\n",
    "\n",
    "if 'mappingfile' not in globals():\n",
    "    print('mappingfile variable is missing')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Download climate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### User Note:\n",
    "\n",
    "Run the next two code blocks if your data is within the Continental United States and you want daily data 1915-2011. <br/>\n",
    "View data extent at  Livneh, B. (2017). Gridded climatology locations (1/16th degree): Continental United States extent, HydroShare, http://www.hydroshare.org/resource/14f0a6619c6b45cc90d1f8cabc4129af\n",
    "\n",
    "### Get Daily Meteorologic Data (1915-2011) from Livneh et al. 2013 \n",
    "Please cite: <br/>\n",
    "Livneh B., E.A. Rosenberg, C. Lin, B. Nijssen, V. Mishra, K.M. Andreadis, E.P. Maurer, and D.P. Lettenmaier, 2013: A Long-Term Hydrologically Based Dataset of Land Surface Fluxes and States for the Conterminous United States: Update and Extensions, Journal of Climate, 26, 9384â€“9392.\n",
    "\n",
    "## Landlab Developer Note:  proposed Landlab function = getClimateData_DailyMET_Livneh2013()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From the reference mapping file, read-in, download, and unzip the data files for the longitude and latitude points\n",
    "Daily_MET_1915_2011 = pypeline_scripts.getClimateData_DailyMET_livneh2013(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## User Note:\n",
    "\n",
    "Run the next two code blocks if your data is within the North America area and you want daily data 1950-2013. View the data extent from this HydroShare resource: Livneh, B. (2017). Gridded climatology locations (1/16th degree): North American extent, HydroShare,  http://www.hydroshare.org/resource/ef2d82bf960144b4bfb1bae6242bcc7f\n",
    "\n",
    "### Get VIC fluxes (1915-2011) from Livneh et al. 2013\n",
    "\n",
    "Please cite: <br/>\n",
    "Livneh B., T.J. Bohn, D.S. Pierce, F. Munoz-Ariola, B. Nijssen, R. Vose, D. Cayan, and L.D. Brekke, 2015: A spatially comprehensive, hydrometeorological data set for Mexico, the U.S., and southern Canada 1950-2013, Nature Scientific Data, 5:150042, doi:10.1038/sdata.2015.42.\n",
    "\n",
    "## Landlab Developer Note:  proposed Landlab function = getClimateData_daily_Livneh2016()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utilities import pypeline_scripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.09375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.03125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.21875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.78125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.15625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.71875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.09375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.96875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.03125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.71875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.40625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.96875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.15625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.90625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.34375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.09375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.90625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.40625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.28125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.40625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.84375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.84375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.03125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.21875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.34375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.34375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.78125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.78125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-120.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.96875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.03125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.15625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.28125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.40625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.09375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.21875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.28125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-120.71875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.90625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-120.96875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.34375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-120.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.15625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.21875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.40625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.34375_-121.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.28125_-121.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-120.84375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-120.90625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.21875_-121.28125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-120.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-121.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-120.96875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-120.53125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.34375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.53125_-121.34375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.53125_-120.90625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-120.84375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.53125_-120.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.59375_-121.28125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-120.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.59375_-120.84375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-120.90625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-120.46875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.28125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.53125_-121.28125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.53125_-120.84375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.40625_-120.78125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.59375_-121.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.59375_-121.21875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.59375_-121.59375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-120.84375 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.59375_-120.78125 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.53125_-121.65625 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.46875_-121.21875 unzipped\n",
      "VIC_subdaily_fluxes_Livneh_CONUSExt_v.1.2_2013_48.59375_-121.53125 unzipped\n"
     ]
    }
   ],
   "source": [
    "# read in the longitude and latitude points from the reference mapping file\n",
    "Daily_VIC_1915_2011 = pypeline_scripts.getClimateData_DailyVIC_Livneh2013(homedir, mappingfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the results back into HydroShare\n",
    "<a name=\"creation\"></a>\n",
    "\n",
    "Using the `hs_utils` library, the results of the Geoprocessing steps above can be saved back into HydroShare.  First, define all of the required metadata for resource creation, i.e. *title*, *abstract*, *keywords*, *content files*.  In addition, we must define the type of resource that will be created, in this case *genericresource*.  \n",
    "\n",
    "***Note:*** Make sure you save the notebook at this point, so that all notebook changes will be saved into the new HydroShare resource.\n",
    "\n",
    "\n",
    "***Option A*** : define the resource from which this \"NEW\" content has been derived.  This is one method for tracking resource provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Daily_MET_1915_2011\n",
    "if 'Daily_MET_1915_2011' not in locals():\n",
    "    Daily_MET_1915_2011 = ''.join([homedir, 'livneh2013/', 'Daily_MET_1915_2011/'])\n",
    "    \n",
    "# MET_1950_2013\n",
    "if 'Daily_MET_1950_2013' not in locals():\n",
    "    Daily_MET_1950_2013 = ''.join([homedir, 'livneh2016/', 'Daily_MET_1950_2013/'])\n",
    "\n",
    "# VIC_1950-2013\n",
    "if 'VIC_1950_2013' not in locals():\n",
    "    VIC_1950_2013 = ''.join([homedir, 'livneh2016/', 'VIC_1950-2013/'])\n",
    "\n",
    "print Daily_MET_1915_2011\n",
    "print Daily_MET_1950_2013\n",
    "print VIC_1950_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list of files with their paths to be added to the HydroShare resource.\n",
    "files = pypeline_scripts.compileContentfiles(Daily_MET_1915_2011)\n",
    "print files[0]  #print example files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for each file downloaded onto the server folder, move to a new HydroShare Generic Resource\n",
    "title = 'Climate Data Download for Sauk Watershed' # title for the new resource\n",
    "abstract = 'This a download of climate data and vizualization processing results from the Daily_MET_1915_2011 (Livneh et al. 2013); Livneh B., E.A. Rosenberg, C. Lin, B. Nijssen, V. Mishra, K.M. Andreadis, E.P. Maurer, and D.P. Lettenmaier, 2013: A Long-Term Hydrologically Based Dataset of Land Surface Fluxes and States for the Conterminous United States: Update and Extensions, Journal of Climate, 26, 9384â€“9392.' # abstract for the new resource\n",
    "keywords = ['Livneh', 'climate', 'watershed'] # keywords for the new resource\n",
    "rtype = 'genericresource'          # Hydroshare resource type\n",
    "\n",
    "# create the new resource\n",
    "resource_id = hs.createHydroShareResource(abstract, \n",
    "                                          title, \n",
    "                                          derivedFromId=os.environ['HS_RES_ID'],\n",
    "                                          keywords=keywords, \n",
    "                                          resource_type=rtype, \n",
    "                                          content_files=files, \n",
    "                                          public=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Option B*** : Move each file on the server within the 'files' list to an :EXISTING\" HydroShare Generic Resource content folder.  Parent_resource is the destination resource ID for an existing Generic Resource. Files is a list of filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parent_resource = 'e77d01d7d1084be396bf783bd8d3c7e4'\n",
    "#response_json = hs.addContentToExistingResource(parent_resource, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Visualizations of Daily, Monthly and Annual Hydroclimatology Data\n",
    "\n",
    "This section performs computations and generates plots of the Livneh 2013 and 2016 climate temperature and precipitation data in order to compare them with each other and observations. The generated plots are automatically downloaded and saved as .png files in the \"plots\" folder of the user's home directory. The plots will also appear inline in the notebook as they are generated such that the user has the flexibility to modify and replace the plots as desired.<br/><br/>\n",
    "This section has the optional functionality to import and compare an additional set of temperature and precipitation data; observed streamflow data (e.g., downloded from a USGS streamflow gage); and modeled streamflow data. Throughout the notebook, there are steps the user must take depending on the additional data they would like to analyze and plot.\n",
    "<br/><br/>\n",
    "First we must import necessary libraries. The libraries csv, pandas, datetime and numpy are used for computations. The libraries matplotlib and OrderedDict used for plotting. The %matplotlib inline command tells the notebook server to place plots and figures directly into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5A.  INPUT: Read in watershed data to include in plots of gridded climatology\n",
    "INPUT in single quote the name of the location (loc_name). This name will be displayed on the plots. <br/> <br/>\n",
    "INPUT ('Y' or 'N') whether an additional set of daily precipitation data (e.g., bias-corrected data); SNOTEL observations of temperature and precipitation; observed streamflow data (e.g., downloaded from a USGS streamflow gage); and modeled streamflow data will be included in the analysis. For any additional files, include what the name of the input files is (..._file) and the name of the location/source to be displayed on plots (..._name). If the user is analyzing streamflow (observed or modeled data), the drainage area to the streamflow gage in units of square meters is to be entered (streamflow_obs_drainage_area or streamflow_mod_drainage_area). The format of the input file should be the same as those included in this example; otherwise, the code shall be appropriately modified. If the user is not analyzing any of these additional data, the variables can be set as ''."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: Location Name and watershed drainage area (m2)\n",
    " These files are all supplied to the home directory (homedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_name='Sauk Watershed'\n",
    "streamflow_watershed_drainage_area=1849242318 # square meters- Sauk watershed\n",
    "\n",
    "#loc_name='Elwha Watershed'\n",
    "#streamflow_watershed_drainage_area=697277794 #square meters- Elwha watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: Observed streamflow\n",
    "If you want to plot observed streamflow with the gridded climate data, set to 'Y' <br/>\n",
    "Give name of observed streamflow file, drainage area upstream of gage, and station name to be used in figure legends. <br/>\n",
    "File format: tab delimited with four columns with streamflow in cubic feet per second (cfs)  <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INPUT name of observed streamflow file and revise commands as necessary.\n",
    "# Format should match the example- text file with columns for year, month, day, and streamflow in [cfs]\n",
    "# If in a different format then need to modify code appropriately\n",
    "\n",
    "streamflow_obs_file=homedir+'SaukRiver_Sauk_obs_cfs.dly.txt'\n",
    "streamflow_obs_file_colnames=['year','month','day','flow_cfs']\n",
    "\n",
    "# generate the streamflow_obs_daily\n",
    "streamflow_obs_daily = pypeline_scripts.read_daily_streamflow(file_name=streamflow_obs_file,\n",
    "                                             file_colnames=streamflow_obs_file_colnames,\n",
    "                                             delimiter='\\t',\n",
    "                                             drainage_area_m2=streamflow_watershed_drainage_area)\n",
    "\n",
    "# Check data frame\n",
    "streamflow_obs_daily[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: Modeled streamflow\n",
    "If you want to plot modeled streamflow with the gridded climate data, set to 'Y' \n",
    "Give name of modeled streamflow file, drainage area upstream of modeled location, and model name to be used in figure legends. \n",
    "File format: tab delimited with four columns with streamflow in cubic meters per second (cms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INPUT name of observed streamflow file and revise commands as necessary.\n",
    "# Format should match the example- text file with columns for year, month, day, and streamflow in [cfs]\n",
    "# If in a different format then need to modify code appropriately\n",
    "\n",
    "streamflow_mod_file=homedir+'12189500.streamflow.daily.cms.txt'\n",
    "streamflow_mod_file_colnames=['year','month','day','flow_cms']\n",
    "\n",
    "# generate the streamflow_obs_daily\n",
    "streamflow_mod_daily = pypeline_scripts.read_daily_streamflow(file_name=streamflow_mod_file,\n",
    "                                             file_colnames=streamflow_mod_file_colnames,\n",
    "                                             delimiter='\\s+',\n",
    "                                             drainage_area_m2=streamflow_watershed_drainage_area)\n",
    "\n",
    "# Check data frame\n",
    "streamflow_mod_daily[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: Modeled precipitation (PRISM, bias correction, any other climate dataset, etc.)\n",
    "If you want to plot modeled average precipitation with the gridded climate data, set to 'Y' <br/>\n",
    "Give name of modeled precipitation file and model name to be used in figure legends. <br/>\n",
    "File format: space delimited with four columns with precipitation in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precip_mod_file=homedir+'Precip.daily.m.txt'\n",
    "precip_mod_file_colnames=['year','month','day','precip_m']\n",
    "precip_mod_name='CIG BC Liv 2013'\n",
    "\n",
    "# generate the streamflow_obs_daily\n",
    "precip_mod_daily = pypeline_scripts.read_daily_precip(file_name=precip_mod_file,\n",
    "                                     file_colnames=precip_mod_file_colnames,\n",
    "                                     delimiter='\\s+')\n",
    "\n",
    "# Check data frame\n",
    "precip_mod_daily[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: Observed SNOTEL data \n",
    "If you want to plot observed snotel point precipitation or temperature with the gridded climate data, set to 'Y' \n",
    "Give name of Snotel file and name to be used in figure legends. \n",
    "File format: Daily SNOTEL Data Report - Historic - By individual SNOTEL site, standard sensors (https://www.wcc.nrcs.usda.gov/snow/snotel-data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SNOTEL_file=homedir+'Buckinghorse_SNOTEL.txt' # Sauk\n",
    "SNOTEL_station_name='Buckinghorse River'\n",
    "SNOTEL_file_use_colsnames = ['Date','Air Temperature Maximum (degF)', 'Air Temperature Minimum (degF)','Air Temperature Average (degF)','Precipitation Increment (in)']\n",
    "SNOTEL_station_elev=int(4320/3.281) # meters\n",
    "\n",
    "\n",
    "SNOTEL_obs_daily = pypeline_scripts.read_daily_snotel(file_name=SNOTEL_file,\n",
    "                                     usecols=SNOTEL_file_use_colsnames,\n",
    "                                     delimiter=',',\n",
    "                                     header=58)\n",
    "# generate the start and stop date\n",
    "SNOTEL_obs_start_date=SNOTEL_obs_daily.index[0]\n",
    "SNOTEL_obs_end_date=SNOTEL_obs_daily.index[-1]\n",
    "\n",
    "# peek\n",
    "SNOTEL_obs_daily[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5B. INPUT: gridded meteorology from Jupyter Hub folders\n",
    "Next, the mapping file of the climate stations is uploaded. The file must include columns with station numbers (this can be aribitrary), latitude, longitude, and elevation. The header of these columns must be FID, LAT, LONG_, and ELEV or RASTERVALU, respectively. These 4 field will be stored in a data frame called \"climate_locations_df\". The station numbers will be used for the remainder of the code to uniquely reference data from each climate station, and will be the same for each dataset.\n",
    "The code block will return entries of the first two climate stations in climate_locations_df. The code block will also return the number of climate stations and minimum, maximum, and average elevation of all of the climate stations. These elevations are useful because, later, there is the option to analyze and plot data for either the full elevation range or a specific elevation range identified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate the mapping\n",
    "climate_locations_df, n_stations = pypeline_scripts.mappingfileToDF(mappingfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read in all of the downloaded Livneh 2013 and 2016 daily meteorology files. Climate data for each station (daily max temperature, min temperature, precipitation and windspeed) will be stored in a data frame. Data frames for each set of Livneh data will be stored in a list. First we define a function to do this and then run this function for the 2013 and 2016 Livneh data. The function will return the first 10 lines of the first station's data frame. <br/>\n",
    " <br/>\n",
    " Known issue: this code assumes that the order of the stations corresponds to the Lat/Long order in the mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Upload Livneh 2013 meteorology data\n",
    "# compile name of Livneh 2013 met data files\n",
    "liv2013_all_daily = pypeline_scripts.read_in_all_met_files(file_names = filesWithPath(Daily_MET_1915_2011),\n",
    "                                          start_date = datetime.date(1915,1,1),\n",
    "                                          end_date = datetime.date(2011,12,31))\n",
    "\n",
    "# identify the datetime indices from the first table\n",
    "liv2013_all_daily_dates=list(liv2013_all_daily[0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Upload Livneh 2016 meteorology data\n",
    "liv2016_all_daily = read_in_all_met_files(file_names = filesWithPath(Daily_MET_1950_2013),\n",
    "                                          start_date = datetime.date(1950,1,1),\n",
    "                                          end_date = datetime.date(2013,12,31))\n",
    "liv2016_all_daily_dates=list(liv2016_all_daily[0].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5C. Arrange variables for spatial averaging\n",
    "Create numpy arrays and pandas data frames for each variable of interest (Tmin, Tmax, Precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate the Variable tables for 2013\n",
    "[temp_min_liv2013_met_daily_df, \n",
    " temp_max_liv2013_met_daily_df, \n",
    " precip_liv2013_met_daily_df, \n",
    " wind_liv2013_met_daily_df,\n",
    " temp_avg_liv2013_met_daily_df]=generateVarTables (liv2013_all_daily_dates, liv2013_all_daily, n_stations)\n",
    "\n",
    "# generate the Variable tables for 2016\n",
    "[temp_min_liv2016_met_daily_df, \n",
    " temp_max_liv2016_met_daily_df, \n",
    " precip_liv2016_met_daily_df, \n",
    " wind_liv2016_met_daily_df,\n",
    " temp_avg_liv2016_met_daily_df]=generateVarTables (liv2016_all_daily_dates, liv2016_all_daily, n_stations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INPUT elevation range and date range of interest for plots- uncomment option of interest\n",
    "# Use full watershed area\n",
    "min_elev=climate_locations_df.elevation.min()\n",
    "max_elev=climate_locations_df.elevation.max()\n",
    "\n",
    "start_date, end_date = overlappingDates(liv2013_all_daily_dates, liv2016_all_daily_dates)\n",
    "print start_date\n",
    "print end_date\n",
    "\n",
    "#%% Calculations for plots\n",
    "days_per_month=[31, 28.25, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "days_per_year=365.25\n",
    "\n",
    "# NEED adjust the date to the nearest water year cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate means by 8 different methods\n",
    "def aggregate_space_time_temperature(VarTable, n_stations, start_date, end_date):\n",
    "    Var_daily = VarTable.loc[start_date:end_date, range(0,n_stations)]\n",
    "    \n",
    "    # e.g., Mean monthly temperature at each station\n",
    "    month_daily=Var_daily.groupby(Var_daily.index.month).mean() \n",
    "    \n",
    "    # e.g., Mean monthly temperature averaged for all stations in analysis\n",
    "    meanmonth_daily=month_daily.mean(axis=1)\n",
    "    \n",
    "    # e.g., Mean monthly temperature for minimum and maximum elevation stations\n",
    "    meanmonth_min_maxelev_daily=Var_daily.loc[:,analysis_elev_max_station].groupby(Var_daily.index.month).mean()\n",
    "    meanmonth_min_minelev_daily=Var_daily.loc[:,analysis_elev_min_station].groupby(Var_daily.index.month).mean()\n",
    "    \n",
    "    # e.g., Mean annual temperature\n",
    "    year_daily=Var_daily.groupby(Var_daily.index.year).mean()\n",
    "    \n",
    "    # e.g., mean annual temperature each year for all stations\n",
    "    meanyear_daily=year_daily.mean(axis=1)\n",
    "    \n",
    "    # e.g., mean annual min temperature for all years, for all stations\n",
    "    meanallyear_daily=np.nanmean(meanyear_daily)\n",
    "    \n",
    "    # e.g., anomoly per year compared to average\n",
    "    anom_year_daily=meanyear_daily-meanallyear_daily\n",
    "    \n",
    "    return(month_daily, \n",
    "           meanmonth_daily, \n",
    "           meanmonth_min_maxelev_daily, \n",
    "           meanmonth_min_minelev_daily, \n",
    "           year_daily, \n",
    "           meanyear_daily, \n",
    "           meanallyear_daily,\n",
    "           anom_year_daily)\n",
    "\n",
    "def specialTavgMeans(VarTable):\n",
    "    Var_daily = VarTable.loc[start_date:end_date, range(0,n_stations)]\n",
    "    \n",
    "    # Average temperature for each month at each station\n",
    "    permonth_daily=Var_daily.groupby(pandas.TimeGrouper(\"M\")).mean()\n",
    "    \n",
    "    # Average temperature each month averaged at all stations\n",
    "    meanpermonth_daily=permonth_daily.mean(axis=1)\n",
    "    \n",
    "    # Average monthly temperature for all stations\n",
    "    meanallpermonth_daily=meanpermonth_daily.mean(axis=0)\n",
    "    \n",
    "    # anomoly per year compared to average\n",
    "    anom_month_daily=(meanpermonth_daily-meanallpermonth_daily)/1000\n",
    "    \n",
    "    return(permonth_daily,\n",
    "          meanpermonth_daily,\n",
    "          meanallpermonth_daily,\n",
    "          anom_month_daily)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create date frames that include the extent of analysis only\n",
    "# Find points in elevation range of interest\n",
    "analysis_stations_info=climate_locations_df[(climate_locations_df.elevation >= min_elev) & (climate_locations_df.elevation <= max_elev)]\n",
    "\n",
    "# Extract list of station numbers for indexing. Alternative, you can set the list of stations manually!\n",
    "analysis_elev_min_station=analysis_stations_info.elevation.idxmin() # station of minimum elevation in analysis\n",
    "analysis_elev_min=analysis_stations_info.elevation.min() # minimum elevaiton of stations in analysis\n",
    "\n",
    "analysis_elev_max_station=analysis_stations_info.elevation.idxmax() # station of maximum elevation in analysis\n",
    "analysis_elev_max=analysis_stations_info.elevation.max() # maximum elevaiton of stations in analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the typical mean values for each of the variables (Tmin, Tmax, Tavg, Precip, & Wind) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate vectors of each calculation TEMP MIN 2013\n",
    "[month_temp_min_analysis_liv2013_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_temp_min_analysis_liv2013_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_temp_min_analysis_maxelev_liv2013_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_temp_min_analysis_minelev_liv2013_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_temp_min_analysis_liv2013_met_daily, # Mean annual temperature\n",
    " meanyear_temp_min_analysis_liv2013_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_temp_min_analysis_liv2013_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_temp_min_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(temp_min_liv2013_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation TEMP MIN 2016\n",
    "[month_temp_min_analysis_liv2016_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_temp_min_analysis_liv2016_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_temp_min_analysis_maxelev_liv2016_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_temp_min_analysis_minelev_liv2016_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_temp_min_analysis_liv2016_met_daily, # Mean annual temperature\n",
    " meanyear_temp_min_analysis_liv2016_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_temp_min_analysis_liv2016_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_temp_min_analysis_liv2016_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(temp_min_liv2016_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation TEMP MAX 2013\n",
    "[month_temp_max_analysis_liv2013_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_temp_max_analysis_liv2013_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_temp_max_analysis_maxelev_liv2013_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_temp_max_analysis_minelev_liv2013_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_temp_max_analysis_liv2013_met_daily, # Mean annual temperature\n",
    " meanyear_temp_max_analysis_liv2013_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_temp_max_analysis_liv2013_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_temp_max_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(temp_max_liv2013_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation TEMP MAX 2016\n",
    "[month_temp_max_analysis_liv2016_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_temp_max_analysis_liv2016_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_temp_max_analysis_maxelev_liv2016_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_temp_max_analysis_minelev_liv2016_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_temp_max_analysis_liv2016_met_daily, # Mean annual temperature\n",
    " meanyear_temp_max_analysis_liv2016_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_temp_max_analysis_liv2016_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_temp_max_analysis_liv2016_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(temp_max_liv2016_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation TEMP AVG 2013\n",
    "[month_temp_avg_analysis_liv2013_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_temp_avg_analysis_liv2013_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_temp_avg_analysis_maxelev_liv2013_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_temp_avg_analysis_minelev_liv2013_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_temp_avg_analysis_liv2013_met_daily, # Mean annual temperature\n",
    " meanyear_temp_avg_analysis_liv2013_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_temp_avg_analysis_liv2013_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_temp_avg_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(temp_avg_liv2013_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation TEMP AVG 2016\n",
    "[month_temp_avg_analysis_liv2016_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_temp_avg_analysis_liv2016_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_temp_avg_analysis_maxelev_liv2016_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_temp_avg_analysis_minelev_liv2016_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_temp_avg_analysis_liv2016_met_daily, # Mean annual temperature\n",
    " meanyear_temp_avg_analysis_liv2016_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_temp_avg_analysis_liv2016_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_temp_avg_analysis_liv2016_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(temp_avg_liv2016_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation PRECIP 2013\n",
    "[month_precip_analysis_liv2013_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_precip_analysis_liv2013_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_precip_analysis_maxelev_liv2013_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_precip_analysis_minelev_liv2013_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_precip_analysis_liv2013_met_daily, # Mean annual temperature\n",
    " meanyear_precip_analysis_liv2013_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_precip_analysis_liv2013_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_precip_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(precip_liv2013_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation PRECIP 2016\n",
    "[month_precip_analysis_liv2016_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_precip_analysis_liv2016_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_precip_analysis_maxelev_liv2016_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_precip_analysis_minelev_liv2016_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_precip_analysis_liv2016_met_daily, # Mean annual temperature\n",
    " meanyear_precip_analysis_liv2016_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_precip_analysis_liv2016_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_precip_analysis_liv2016_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(precip_liv2016_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation WIND 2013\n",
    "[month_wind_analysis_liv2013_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_wind_analysis_liv2013_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_wind_analysis_maxelev_liv2013_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_wind_analysis_minelev_liv2013_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_wind_analysis_liv2013_met_daily, # Mean annual temperature\n",
    " meanyear_wind_analysis_liv2013_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_wind_analysis_liv2013_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_wind_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(wind_liv2013_met_daily_df, n_stations, start_date, end_date)\n",
    "\n",
    "\n",
    "# Generate vectors of each calculation WIND 2016\n",
    "[month_wind_analysis_liv2016_met_daily, # Mean monthly temperature at each station\n",
    " meanmonth_wind_analysis_liv2016_met_daily, # Mean monthly temperature averaged for all stations in analysis\n",
    " meanmonth_wind_analysis_maxelev_liv2016_met_daily, # Mean monthly temperature for maximum elevation stations\n",
    " meanmonth_wind_analysis_minelev_liv2016_met_daily, # Mean monthly temperature for minimum elevation stations\n",
    " year_wind_analysis_liv2016_met_daily, # Mean annual temperature\n",
    " meanyear_wind_analysis_liv2016_met_daily, # mean annual temperature each year for all stations\n",
    " meanallyear_wind_analysis_liv2016_met_daily, # mean annual min temperature for all years, for all stations\n",
    " anom_year_wind_analysis_liv2016_met_daily # anomoly per year compared to average\n",
    "] = multigroupMeans(wind_liv2016_met_daily_df, n_stations, start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate special mean values for Temp_avg and Precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the special means for TEMP AVG 2013\n",
    "[permonth_temp_avg_analysis_liv2013_met_daily,\n",
    " meanpermonth_temp_avg_analysis_liv2013_met_daily,\n",
    " meanallpermonth_temp_avg_analysis_liv2013_met_daily,\n",
    " anom_month_temp_avg_analysis_liv2013_met_daily\n",
    "]=specialTavgMeans(temp_avg_liv2013_met_daily_df)\n",
    "\n",
    "# calculate the special means for TEMP AVG 2016\n",
    "[permonth_temp_avg_analysis_liv2016_met_daily,\n",
    " meanpermonth_temp_avg_analysis_liv2016_met_daily,\n",
    " meanallpermonth_temp_avg_analysis_liv2016_met_daily,\n",
    " anom_month_temp_avg_analysis_liv2016_met_daily\n",
    "]=specialTavgMeans(temp_avg_liv2016_met_daily_df)\n",
    "\n",
    "\n",
    "# calculate the special means for PRECIP 2013\n",
    "[permonth_precip_analysis_liv2013_met_daily,\n",
    " meanpermonth_precip_analysis_liv2013_met_daily,\n",
    " meanallpermonth_precip_analysis_liv2013_met_daily,\n",
    " anom_month_precip_analysis_liv2013_met_daily\n",
    "]=specialTavgMeans(precip_liv2013_met_daily_df)\n",
    "\n",
    "# calculate the special means for PRECIP 2016\n",
    "[permonth_precip_analysis_liv2016_met_daily,\n",
    " meanpermonth_precip_analysis_liv2016_met_daily,\n",
    " meanallpermonth_precip_analysis_liv2016_met_daily,\n",
    " anom_month_precip_analysis_liv2016_met_daily\n",
    "]=specialTavgMeans(precip_liv2016_met_daily_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Climate Index\n",
    "CI_liv2013_monthly=(-anom_month_temp_avg_analysis_liv2013_met_daily+anom_month_precip_analysis_liv2013_met_daily)/2\n",
    "CI_liv2016_monthly=(-anom_month_temp_avg_analysis_liv2016_met_daily+anom_month_precip_analysis_liv2016_met_daily)/2\n",
    "\n",
    "CI_liv2013_year=(-anom_year_temp_avg_analysis_liv2013_met_daily+anom_year_precip_analysis_liv2013_met_daily)/2\n",
    "CI_liv2016_year=(-anom_year_temp_avg_analysis_liv2016_met_daily+anom_year_precip_analysis_liv2016_met_daily)/2\n",
    "\n",
    "# Precipitation- Modeled\n",
    "meanmonth_precip_analysis_mod_daily=precip_analysis_mod_daily.groupby(precip_analysis_mod_daily.index.month).mean() # mean daily precip per month\n",
    "month_precip_analysis_mod_daily=days_per_month*meanmonth_precip_analysis_mod_daily # mean monthly precip \n",
    "permonth_precip_analysis_mod_daily=precip_analysis_mod_daily.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "\n",
    "# Streamflow\n",
    "permonth_streamflow_analysis_obs_daily_mmday=streamflow_analysis_obs_daily_mmday.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "permonth_streamflow_analysis_mod_daily_mmday=streamflow_analysis_mod_daily_mmday.groupby(pandas.TimeGrouper(\"M\")).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check for daily streamflow_obs, streamflow_mod, and precip_mod dataframes\n",
    "if 'streamflow_obs_daily' in locals():\n",
    "    streamflow_analysis_obs_daily_mmday=streamflow_obs_daily.flow_mmday[start_date:end_date]\n",
    "\n",
    "if 'precip_mod_daily' in locals():\n",
    "    precip_analysis_mod_daily=precip_mod_daily.precip_mm[start_date:end_date]\n",
    "\n",
    "if 'streamflow_mod_daily' in locals():\n",
    "    streamflow_analysis_mod_daily_mmday=streamflow_mod_daily.flow_mmday[start_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create date frames that include the extent of analysis only\n",
    "# Find points in elevation range of interest\n",
    "analysis_stations_info=climate_locations_df[(climate_locations_df.elevation >= min_elev) & (climate_locations_df.elevation <= max_elev)]\n",
    "\n",
    "# Extract list of station numbers for indexing. Alternative, you can set the list of stations manually!\n",
    "print range(0,n_stations)\n",
    "\n",
    "analysis_elev_min_station=analysis_stations_info.elevation.idxmin() # station of minimum elevation in analysis\n",
    "analysis_elev_min=analysis_stations_info.elevation.min() # minimum elevaiton of stations in analysis\n",
    "\n",
    "analysis_elev_max_station=analysis_stations_info.elevation.idxmax() # station of maximum elevation in analysis\n",
    "analysis_elev_max=analysis_stations_info.elevation.max() # maximum elevaiton of stations in analysis\n",
    "\n",
    "\n",
    "temp_min_analysis_liv2013_met_daily=temp_min_liv2013_met_daily_df.loc[start_date:end_date, range(0,n_stations)]\n",
    "\n",
    "\n",
    "# Mean monthly temperature at each station\n",
    "month_temp_min_analysis_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.groupby(temp_min_analysis_liv2013_met_daily.index.month).mean() # average monthly minimum temperature at each station\n",
    "\n",
    "# Mean monthly temperature averaged for all stations in analysis\n",
    "meanmonth_temp_min_analysis_liv2013_met_daily=month_temp_min_analysis_liv2013_met_daily.mean(axis=1) # average monthly minimum temperature for all stations\n",
    "\n",
    "# Mean monthly temperature for minimum and maximum elevation stations\n",
    "meanmonth_temp_min_analysis_maxelev_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.loc[:,analysis_elev_max_station].groupby(temp_min_analysis_liv2013_met_daily.index.month).mean()\n",
    "\n",
    "# Mean annual temperature\n",
    "year_temp_min_analysis_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.groupby(temp_min_analysis_liv2013_met_daily.index.year).mean()\n",
    "\n",
    "meanyear_temp_min_analysis_liv2013_met_daily=year_temp_min_analysis_liv2013_met_daily.mean(axis=1)  # mean annual min temperature each year for all stations\n",
    "\n",
    "meanallyear_temp_min_analysis_liv2013_met_daily=np.nanmean(meanyear_temp_min_analysis_liv2013_met_daily) # mean annual min temperature for all years, for all stations\n",
    "\n",
    "anom_year_temp_min_analysis_liv2013_met_daily=meanyear_temp_min_analysis_liv2013_met_daily-meanallyear_temp_min_analysis_liv2013_met_daily # anomoly per year compared to average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% Calculations for plots\n",
    "days_per_month=[31, 28.25, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "days_per_year=365.25\n",
    "\n",
    "# Mean monthly temperature at each station\n",
    "month_temp_min_analysis_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.groupby(temp_min_analysis_liv2013_met_daily.index.month).mean() # average monthly minimum temperature at each station\n",
    "month_temp_min_analysis_liv2016_met_daily=temp_min_analysis_liv2016_met_daily.groupby(temp_min_analysis_liv2016_met_daily.index.month).mean()\n",
    "\n",
    "month_temp_max_analysis_liv2013_met_daily=temp_max_analysis_liv2013_met_daily.groupby(temp_max_analysis_liv2013_met_daily.index.month).mean() # average monthly maximum temperature at each station\n",
    "month_temp_max_analysis_liv2016_met_daily=temp_max_analysis_liv2016_met_daily.groupby(temp_max_analysis_liv2016_met_daily.index.month).mean()\n",
    "\n",
    "month_temp_avg_analysis_liv2013_met_daily=temp_avg_analysis_liv2013_met_daily.groupby(temp_avg_analysis_liv2013_met_daily.index.month).mean() # average monthly average temperature at each station\n",
    "month_temp_avg_analysis_liv2016_met_daily=temp_avg_analysis_liv2016_met_daily.groupby(temp_avg_analysis_liv2016_met_daily.index.month).mean()\n",
    "\n",
    "# Mean monthly temperature averaged for all stations in analysis\n",
    "meanmonth_temp_min_analysis_liv2013_met_daily=month_temp_min_analysis_liv2013_met_daily.mean(axis=1) # average monthly minimum temperature for all stations\n",
    "meanmonth_temp_min_analysis_liv2016_met_daily=month_temp_min_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanmonth_temp_max_analysis_liv2013_met_daily=month_temp_max_analysis_liv2013_met_daily.mean(axis=1) # average monthly maximum temperature for all stations\n",
    "meanmonth_temp_max_analysis_liv2016_met_daily=month_temp_max_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanmonth_temp_avg_analysis_liv2013_met_daily=month_temp_avg_analysis_liv2013_met_daily.mean(axis=1) # average monthly average temperature for all stations\n",
    "meanmonth_temp_avg_analysis_liv2016_met_daily=month_temp_avg_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "# Mean monthly temperature for minimum and maximum elevation stations\n",
    "meanmonth_temp_min_analysis_maxelev_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.loc[:,analysis_elev_max_station].groupby(temp_min_analysis_liv2013_met_daily.index.month).mean()\n",
    "meanmonth_temp_min_analysis_minelev_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.loc[:,analysis_elev_min_station].groupby(temp_min_analysis_liv2013_met_daily.index.month).mean()\n",
    "\n",
    "meanmonth_temp_max_analysis_maxelev_liv2013_met_daily=temp_max_analysis_liv2013_met_daily.loc[:,analysis_elev_max_station].groupby(temp_max_analysis_liv2013_met_daily.index.month).mean()\n",
    "meanmonth_temp_max_analysis_minelev_liv2013_met_daily=temp_max_analysis_liv2013_met_daily.loc[:,analysis_elev_min_station].groupby(temp_max_analysis_liv2013_met_daily.index.month).mean()\n",
    "\n",
    "meanmonth_temp_avg_analysis_maxelev_liv2013_met_daily=temp_avg_analysis_liv2013_met_daily.loc[:,analysis_elev_max_station].groupby(temp_avg_analysis_liv2013_met_daily.index.month).mean()\n",
    "meanmonth_temp_avg_analysis_minelev_liv2013_met_daily=temp_avg_analysis_liv2013_met_daily.loc[:,analysis_elev_min_station].groupby(temp_avg_analysis_liv2013_met_daily.index.month).mean()\n",
    "\n",
    "\n",
    "\n",
    "# Average temperature for each individual month at each station\n",
    "permonth_temp_avg_analysis_liv2013_met_daily=temp_avg_analysis_liv2013_met_daily.groupby(pandas.TimeGrouper(\"M\")).mean() # average temperature each month at each station\n",
    "permonth_temp_avg_analysis_liv2016_met_daily=temp_avg_analysis_liv2016_met_daily.groupby(pandas.TimeGrouper(\"M\")).mean()\n",
    "\n",
    "# Average temperature each month averaged at all stations\n",
    "meanpermonth_temp_avg_analysis_liv2013_met_daily=permonth_temp_avg_analysis_liv2013_met_daily.mean(axis=1) # temperature each month averaged across all stations\n",
    "meanpermonth_temp_avg_analysis_liv2016_met_daily=permonth_temp_avg_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallpermonth_temp_avg_analysis_liv2013_met_daily=meanpermonth_temp_avg_analysis_liv2013_met_daily.mean(axis=0) # Average monthly temperature for all stations\n",
    "meanallpermonth_temp_avg_analysis_liv2016_met_daily=meanpermonth_temp_avg_analysis_liv2016_met_daily.mean(axis=0)\n",
    "\n",
    "anom_month_temp_avg_analysis_liv2013_met_daily=(meanpermonth_temp_avg_analysis_liv2013_met_daily-meanallpermonth_temp_avg_analysis_liv2013_met_daily)/1000 # anomoly per year compared to average\n",
    "anom_month_temp_avg_analysis_liv2016_met_daily=(meanpermonth_temp_avg_analysis_liv2016_met_daily-meanallpermonth_temp_avg_analysis_liv2016_met_daily)/1000\n",
    "\n",
    "\n",
    "# Mean annual temperature\n",
    "year_temp_min_analysis_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.groupby(temp_min_analysis_liv2013_met_daily.index.year).mean()\n",
    "year_temp_min_analysis_liv2016_met_daily=temp_min_analysis_liv2016_met_daily.groupby(temp_min_analysis_liv2016_met_daily.index.year).mean()\n",
    "\n",
    "meanyear_temp_min_analysis_liv2013_met_daily=year_temp_min_analysis_liv2013_met_daily.mean(axis=1)  # mean annual min temperature each year for all stations\n",
    "meanyear_temp_min_analysis_liv2016_met_daily=year_temp_min_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallyear_temp_min_analysis_liv2013_met_daily=np.nanmean(meanyear_temp_min_analysis_liv2013_met_daily) # mean annual min temperature for all years, for all stations\n",
    "meanallyear_temp_min_analysis_liv2016_met_daily=np.nanmean(meanyear_temp_min_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_year_temp_min_analysis_liv2013_met_daily=meanyear_temp_min_analysis_liv2013_met_daily-meanallyear_temp_min_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "anom_year_temp_min_analysis_liv2016_met_daily=meanyear_temp_min_analysis_liv2016_met_daily-meanallyear_temp_min_analysis_liv2016_met_daily\n",
    "\n",
    "year_temp_max_analysis_liv2013_met_daily=temp_max_analysis_liv2013_met_daily.groupby(temp_max_analysis_liv2013_met_daily.index.year).mean()\n",
    "year_temp_max_analysis_liv2016_met_daily=temp_max_analysis_liv2016_met_daily.groupby(temp_max_analysis_liv2016_met_daily.index.year).mean()\n",
    "\n",
    "meanyear_temp_max_analysis_liv2013_met_daily=year_temp_max_analysis_liv2013_met_daily.mean(axis=1)  # mean annual max temperature each year for all stations\n",
    "meanyear_temp_max_analysis_liv2016_met_daily=year_temp_max_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallyear_temp_max_analysis_liv2013_met_daily=np.nanmean(meanyear_temp_max_analysis_liv2013_met_daily) # mean annual max temperature for all years, for all stations\n",
    "meanallyear_temp_max_analysis_liv2016_met_daily=np.nanmean(meanyear_temp_max_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_year_temp_max_analysis_liv2013_met_daily=meanyear_temp_max_analysis_liv2013_met_daily-meanallyear_temp_max_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "anom_year_temp_max_analysis_liv2016_met_daily=meanyear_temp_max_analysis_liv2016_met_daily-meanallyear_temp_max_analysis_liv2016_met_daily\n",
    "\n",
    "year_temp_avg_analysis_liv2013_met_daily=temp_avg_analysis_liv2013_met_daily.groupby(temp_avg_analysis_liv2013_met_daily.index.year).mean() # mean annual avg temperature for each year at all stations\n",
    "year_temp_avg_analysis_liv2016_met_daily=temp_avg_analysis_liv2016_met_daily.groupby(temp_avg_analysis_liv2016_met_daily.index.year).mean()\n",
    "\n",
    "meanyear_temp_avg_analysis_liv2013_met_daily=year_temp_avg_analysis_liv2013_met_daily.mean(axis=1)  # mean annual avg temperature each year for all stations\n",
    "meanyear_temp_avg_analysis_liv2016_met_daily=year_temp_avg_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallyear_temp_avg_analysis_liv2013_met_daily=np.nanmean(meanyear_temp_avg_analysis_liv2013_met_daily) # mean annual avg temperature for all years, for all stations\n",
    "meanallyear_temp_avg_analysis_liv2016_met_daily=np.nanmean(meanyear_temp_avg_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_year_temp_avg_analysis_liv2013_met_daily=meanyear_temp_avg_analysis_liv2013_met_daily-meanallyear_temp_avg_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "anom_year_temp_avg_analysis_liv2016_met_daily=meanyear_temp_avg_analysis_liv2016_met_daily-meanallyear_temp_avg_analysis_liv2016_met_daily\n",
    "\n",
    "\n",
    "# Precipitation- Livneh\n",
    "# Monthly\n",
    "permonth_precip_analysis_liv2013_met_daily=precip_analysis_liv2013_met_daily.groupby(pandas.TimeGrouper(\"M\")).sum() # total precipitation each month at each station\n",
    "permonth_precip_analysis_liv2016_met_daily=precip_analysis_liv2016_met_daily.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "\n",
    "meanpermonth_precip_analysis_liv2013_met_daily=permonth_precip_analysis_liv2013_met_daily.mean(axis=1) # total precipitation each month averaged across all stations\n",
    "meanpermonth_precip_analysis_liv2016_met_daily=permonth_precip_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallpermonth_precip_analysis_liv2013_met_daily=meanpermonth_precip_analysis_liv2013_met_daily.mean(axis=0) # total precipitation each month averaged across all stations\n",
    "meanallpermonth_precip_analysis_liv2016_met_daily=meanpermonth_precip_analysis_liv2016_met_daily.mean(axis=0)\n",
    "\n",
    "anom_month_precip_analysis_liv2013_met_daily=(meanpermonth_precip_analysis_liv2013_met_daily-meanallpermonth_precip_analysis_liv2013_met_daily)/1000 # anomoly per year compared to average\n",
    "anom_month_precip_analysis_liv2016_met_daily=(meanpermonth_precip_analysis_liv2016_met_daily-meanallpermonth_precip_analysis_liv2016_met_daily)/1000\n",
    "\n",
    "meanmonth_precip_analysis_liv2013_met_daily=precip_analysis_liv2013_met_daily.groupby(precip_analysis_liv2013_met_daily.index.month).mean() # mean daily precip per month at each station\n",
    "meanmonth_precip_analysis_liv2016_met_daily=precip_analysis_liv2016_met_daily.groupby(precip_analysis_liv2016_met_daily.index.month).mean()\n",
    "\n",
    "month_precip_analysis_liv2013_met_daily=days_per_month*meanmonth_precip_analysis_liv2013_met_daily.mean(axis=1) # mean monthly precip at each station\n",
    "month_precip_analysis_liv2016_met_daily=days_per_month*meanmonth_precip_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "# Mean annual\n",
    "year_precip_analysis_liv2013_met_daily=precip_analysis_liv2013_met_daily.groupby(precip_analysis_liv2013_met_daily.index.year).sum() # anunual precip at each station\n",
    "year_precip_analysis_liv2016_met_daily=precip_analysis_liv2016_met_daily.groupby(precip_analysis_liv2016_met_daily.index.year).sum()\n",
    "\n",
    "meanyear_precip_analysis_liv2013_met_daily=year_precip_analysis_liv2013_met_daily.mean(axis=1) # mean annual precipitation each year for all stations\n",
    "meanyear_precip_analysis_liv2016_met_daily=year_precip_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallyear_precip_analysis_liv2013_met_daily=np.nanmean(meanyear_precip_analysis_liv2013_met_daily) # mean annual precipitation for all years, for all stations\n",
    "meanallyear_precip_analysis_liv2016_met_daily=np.nanmean(meanyear_precip_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_year_precip_analysis_liv2013_met_daily=(meanyear_precip_analysis_liv2013_met_daily-meanallyear_precip_analysis_liv2013_met_daily)/1000 # anomoly per year compared to average\n",
    "anom_year_precip_analysis_liv2016_met_daily=(meanyear_precip_analysis_liv2016_met_daily-meanallyear_precip_analysis_liv2016_met_daily)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wind- Livneh\n",
    "meanmonth_wind_analysis_liv2013_met_daily=wind_analysis_liv2013_met_daily.groupby(wind_analysis_liv2013_met_daily.index.month).mean()\n",
    "meanmonth_wind_analysis_liv2016_met_daily=wind_analysis_liv2016_met_daily.groupby(wind_analysis_liv2016_met_daily.index.month).mean()\n",
    "\n",
    "# Climate Index\n",
    "CI_liv2013_monthly=(-anom_month_temp_avg_analysis_liv2013_met_daily+anom_month_precip_analysis_liv2013_met_daily)/2\n",
    "CI_liv2016_monthly=(-anom_month_temp_avg_analysis_liv2016_met_daily+anom_month_precip_analysis_liv2016_met_daily)/2\n",
    "\n",
    "CI_liv2013_year=(-anom_year_temp_avg_analysis_liv2013_met_daily+anom_year_precip_analysis_liv2013_met_daily)/2\n",
    "CI_liv2016_year=(-anom_year_temp_avg_analysis_liv2016_met_daily+anom_year_precip_analysis_liv2016_met_daily)/2\n",
    "\n",
    "# Precipitation- Modeled\n",
    "meanmonth_precip_analysis_mod_daily=precip_analysis_mod_daily.groupby(precip_analysis_mod_daily.index.month).mean() # mean daily precip per month\n",
    "month_precip_analysis_mod_daily=days_per_month*meanmonth_precip_analysis_mod_daily # mean monthly precip \n",
    "permonth_precip_analysis_mod_daily=precip_analysis_mod_daily.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "\n",
    "# Streamflow\n",
    "permonth_streamflow_analysis_obs_daily_mmday=streamflow_analysis_obs_daily_mmday.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "permonth_streamflow_analysis_mod_daily_mmday=streamflow_analysis_mod_daily_mmday.groupby(pandas.TimeGrouper(\"M\")).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Annual calculations for water year\n",
    "# Create a matrix of water years- this takes a relatively long time\n",
    "temp_min_analysis_liv2013_met_daily=temp_min_liv2013_met_daily_df.loc[start_date:end_date, range(0,n_stations)]\n",
    "wy_analysis=np.empty(len(temp_min_analysis_liv2013_met_daily))\n",
    "for i in range (0,len(temp_min_analysis_liv2013_met_daily)):\n",
    "    if temp_min_analysis_liv2013_met_daily.index.month[i]>=10:\n",
    "        wy_analysis[i]=int(temp_min_analysis_liv2013_met_daily.index.year[i]+1)\n",
    "    else:\n",
    "        wy_analysis[i]=int(temp_min_analysis_liv2013_met_daily.index.year[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new data frames where index is water year\n",
    "\n",
    "def wateryearIndex()\n",
    "def multigroupMeans_wy()\n",
    "temp_min_analysis_liv2013_met_daily_wy=temp_min_analysis_liv2013_met_daily.copy(deep=True)\n",
    "temp_min_analysis_liv2016_met_daily_wy=temp_min_analysis_liv2016_met_daily.copy(deep=True)\n",
    "temp_max_analysis_liv2013_met_daily_wy=temp_max_analysis_liv2013_met_daily.copy(deep=True)\n",
    "temp_max_analysis_liv2016_met_daily_wy=temp_max_analysis_liv2016_met_daily.copy(deep=True)\n",
    "temp_avg_analysis_liv2013_met_daily_wy=temp_avg_analysis_liv2013_met_daily.copy(deep=True)\n",
    "temp_avg_analysis_liv2016_met_daily_wy=temp_avg_analysis_liv2016_met_daily.copy(deep=True)\n",
    "precip_analysis_liv2013_met_daily_wy=precip_analysis_liv2013_met_daily.copy(deep=True)\n",
    "precip_analysis_liv2016_met_daily_wy=precip_analysis_liv2016_met_daily.copy(deep=True)\n",
    "\n",
    "temp_min_analysis_liv2013_met_daily_wy.index=wy_analysis\n",
    "temp_min_analysis_liv2016_met_daily_wy.index=wy_analysis\n",
    "temp_max_analysis_liv2013_met_daily_wy.index=wy_analysis\n",
    "temp_max_analysis_liv2016_met_daily_wy.index=wy_analysis\n",
    "temp_avg_analysis_liv2013_met_daily_wy.index=wy_analysis\n",
    "temp_avg_analysis_liv2016_met_daily_wy.index=wy_analysis\n",
    "precip_analysis_liv2013_met_daily_wy.index=wy_analysis\n",
    "precip_analysis_liv2016_met_daily_wy.index=wy_analysis\n",
    "\n",
    "# Mean annual temperature\n",
    "wyear_temp_min_analysis_liv2013_met_daily=temp_min_analysis_liv2013_met_daily.groupby(temp_min_analysis_liv2013_met_daily_wy.index).mean()\n",
    "wyear_temp_min_analysis_liv2016_met_daily=temp_min_analysis_liv2016_met_daily.groupby(temp_min_analysis_liv2016_met_daily_wy.index).mean()\n",
    "\n",
    "meanwyear_temp_min_analysis_liv2013_met_daily=wyear_temp_min_analysis_liv2013_met_daily.mean(axis=1)  # mean annual min temperature each year for all stations\n",
    "meanwyear_temp_min_analysis_liv2016_met_daily=wyear_temp_min_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallwyear_temp_min_analysis_liv2013_met_daily=np.nanmean(meanwyear_temp_min_analysis_liv2013_met_daily) # mean annual min temperature for all years, for all stations\n",
    "meanallwyear_temp_min_analysis_liv2016_met_daily=np.nanmean(meanwyear_temp_min_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_wyear_temp_min_analysis_liv2013_met_daily=meanwyear_temp_min_analysis_liv2013_met_daily-meanallwyear_temp_min_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "anom_wyear_temp_min_analysis_liv2016_met_daily=meanwyear_temp_min_analysis_liv2016_met_daily-meanallwyear_temp_min_analysis_liv2016_met_daily\n",
    "\n",
    "wyear_temp_max_analysis_liv2013_met_daily=temp_max_analysis_liv2013_met_daily.groupby(temp_max_analysis_liv2013_met_daily_wy.index).mean()\n",
    "wyear_temp_max_analysis_liv2016_met_daily=temp_max_analysis_liv2016_met_daily.groupby(temp_max_analysis_liv2016_met_daily_wy.index).mean()\n",
    "\n",
    "meanwyear_temp_max_analysis_liv2013_met_daily=wyear_temp_max_analysis_liv2013_met_daily.mean(axis=1)  # mean annual max temperature each year for all stations\n",
    "meanwyear_temp_max_analysis_liv2016_met_daily=wyear_temp_max_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallwyear_temp_max_analysis_liv2013_met_daily=np.nanmean(meanwyear_temp_max_analysis_liv2013_met_daily) # mean annual max temperature for all years, for all stations\n",
    "meanallwyear_temp_max_analysis_liv2016_met_daily=np.nanmean(meanwyear_temp_max_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_wyear_temp_max_analysis_liv2013_met_daily=meanwyear_temp_max_analysis_liv2013_met_daily-meanallwyear_temp_max_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "anom_wyear_temp_max_analysis_liv2016_met_daily=meanwyear_temp_max_analysis_liv2016_met_daily-meanallwyear_temp_max_analysis_liv2016_met_daily\n",
    "\n",
    "wyear_temp_avg_analysis_liv2013_met_daily=temp_avg_analysis_liv2013_met_daily.groupby(temp_avg_analysis_liv2013_met_daily_wy.index).mean() # mean annual avg temperature for each year at all stations\n",
    "wyear_temp_avg_analysis_liv2016_met_daily=temp_avg_analysis_liv2016_met_daily.groupby(temp_avg_analysis_liv2016_met_daily_wy.index).mean()\n",
    "\n",
    "meanwyear_temp_avg_analysis_liv2013_met_daily=wyear_temp_avg_analysis_liv2013_met_daily.mean(axis=1)  # mean annual avg temperature each year for all stations\n",
    "meanwyear_temp_avg_analysis_liv2016_met_daily=wyear_temp_avg_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallwyear_temp_avg_analysis_liv2013_met_daily=np.nanmean(meanwyear_temp_avg_analysis_liv2013_met_daily) # mean annual avg temperature for all years, for all stations\n",
    "meanallwyear_temp_avg_analysis_liv2016_met_daily=np.nanmean(meanwyear_temp_avg_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_wyear_temp_avg_analysis_liv2013_met_daily=meanwyear_temp_avg_analysis_liv2013_met_daily-meanallwyear_temp_avg_analysis_liv2013_met_daily # anomoly per year compared to average\n",
    "anom_wyear_temp_avg_analysis_liv2016_met_daily=meanwyear_temp_avg_analysis_liv2016_met_daily-meanallwyear_temp_avg_analysis_liv2016_met_daily\n",
    "\n",
    "# Mean annual precipitation\n",
    "wyear_precip_analysis_liv2013_met_daily=precip_analysis_liv2013_met_daily.groupby(precip_analysis_liv2013_met_daily_wy.index).sum() # anunual precip at each station\n",
    "wyear_precip_analysis_liv2016_met_daily=precip_analysis_liv2016_met_daily.groupby(precip_analysis_liv2016_met_daily_wy.index).sum()\n",
    "\n",
    "meanwyear_precip_analysis_liv2013_met_daily=wyear_precip_analysis_liv2013_met_daily.mean(axis=1) # mean annual precipitation each year for all stations\n",
    "meanwyear_precip_analysis_liv2016_met_daily=wyear_precip_analysis_liv2016_met_daily.mean(axis=1)\n",
    "\n",
    "meanallwyear_precip_analysis_liv2013_met_daily=np.nanmean(meanwyear_precip_analysis_liv2013_met_daily) # mean annual precipitation for all years, for all stations\n",
    "meanallwyear_precip_analysis_liv2016_met_daily=np.nanmean(meanwyear_precip_analysis_liv2016_met_daily)\n",
    "\n",
    "anom_wyear_precip_analysis_liv2013_met_daily=(meanwyear_precip_analysis_liv2013_met_daily-meanallwyear_precip_analysis_liv2013_met_daily)/1000 # anomoly per year compared to average\n",
    "anom_wyear_precip_analysis_liv2016_met_daily=(meanwyear_precip_analysis_liv2016_met_daily-meanallwyear_precip_analysis_liv2016_met_daily)/1000\n",
    "\n",
    "# Climate Index\n",
    "CI_liv2013_wy=(-anom_wyear_temp_avg_analysis_liv2013_met_daily+anom_wyear_precip_analysis_liv2013_met_daily)/2\n",
    "CI_liv2016_wy=(-anom_wyear_temp_avg_analysis_liv2016_met_daily+anom_wyear_precip_analysis_liv2016_met_daily)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make directory to store images of plots and navigate to that directory\n",
    "def ensure_dir(f):\n",
    "    if not os.path.exists(f):\n",
    "        os.makedirs(f)\n",
    "    os.chdir(f)\n",
    "    \n",
    "filedir=homedir+'plots'\n",
    "ensure_dir(filedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 1: Monthly temperature analysis of Livneh data\n",
    "wy_index=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "wy_numbers=[10, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "month_strings=[ 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept']\n",
    "fig, ax=plt.subplots(1,1,figsize=(10, 6))\n",
    "\n",
    "# Tmax\n",
    "plt.plot(wy_index, meanmonth_temp_max_analysis_liv2013_met_daily[wy_numbers],'ro-',linewidth=1, label='Liv Tmax- All Stations')\n",
    "plt.plot(wy_index, meanmonth_temp_max_analysis_maxelev_liv2013_met_daily[wy_numbers],'r*--',linewidth=1, label='Liv Tmax- Max Elev='+str(analysis_elev_max)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_max_analysis_minelev_liv2013_met_daily[wy_numbers],'r^--',linewidth=1, label='Liv Tmax- Min Elev='+str(analysis_elev_min)+'m')\n",
    "\n",
    "#Tmin\n",
    "plt.plot(wy_index, meanmonth_temp_min_analysis_liv2013_met_daily[wy_numbers],'bo-',linewidth=1, label='Liv Tmin- All Stations')\n",
    "plt.plot(wy_index, meanmonth_temp_min_analysis_maxelev_liv2013_met_daily[wy_numbers],'b*--',linewidth=1, label='Liv Tmin- Max Elev='+str(analysis_elev_max)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_min_analysis_minelev_liv2013_met_daily[wy_numbers],'b^--',linewidth=1, label='Liv Tmin- Min Elev='+str(analysis_elev_min)+'m')\n",
    "\n",
    "## Tavg\n",
    "#plt.plot(wy_index, meanmonth_temp_avg_analysis_liv2013_met_daily[wy_numbers],'go-',linewidth=1, label='Liv 2013 Met- Tavg')\n",
    "#plt.plot(wy_index, meanmonth_temp_avg_analysis_liv2016_met_daily[wy_numbers],'g*-',linewidth=1, label='Liv 2016 Met- Tavg')\n",
    "\n",
    "# Highlight 0 line \n",
    "plt.plot([1, 12],[0, 0], 'k-',linewidth=1)\n",
    "\n",
    "plt.xlabel ('Month',fontsize=14)\n",
    "plt.ylabel('Temperature (deg C)',fontsize=14)\n",
    "plt.title(str(loc_name)+'\\nAverage Monthly Max and Min Temperature\\n Years: '+str(start_date.year)+'-'+str(end_date.year)+'; Elevation: '+str(analysis_elev_min)+'m -'+str(analysis_elev_max)+'m', fontsize=16)\n",
    "plt.legend(loc='best')\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(1,12);\n",
    "plt.xticks(wy_index, month_strings);\n",
    "plt.savefig('avg_monthly_temp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 2: Monthly Precipitation\n",
    "fig, ax=plt.subplots(1,1,figsize=(10, 6))\n",
    "plt.plot(wy_index, month_precip_analysis_liv2013_met_daily[wy_numbers],'bo-',linewidth=1, label='Liv 2013 Met')\n",
    "plt.plot(wy_index, month_precip_analysis_liv2016_met_daily[wy_numbers],'co-',linewidth=1, label='Liv 2016 Met')\n",
    "plt.plot(wy_index, month_precip_analysis_mod_daily[wy_numbers],'mo-',linewidth=1, label='Liv 2013 CIG, BC')\n",
    "plt.plot([1, 12],[0, 0], 'k-',linewidth=1)\n",
    "\n",
    "plt.xlabel ('Month',fontsize=14)\n",
    "plt.ylabel('Precipitation (mm)',fontsize=14)\n",
    "plt.title(str(loc_name)+':\\nAverage Monthly Precipitation ('+str(start_date.year)+'-'+str(end_date.year)+')',fontsize=16)\n",
    "plt.legend(loc='best')\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(1,12);\n",
    "plt.xticks(wy_index, month_strings);\n",
    "plt.savefig('avg_monthly_precip.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 3a: Hyetograph versus Observed Runoff\n",
    "# INPUT start and end date of interest in single quotes\n",
    "graph_start_date='10-1-1998'\n",
    "graph_end_date='9-30-1999'\n",
    "\n",
    "# Create plot\n",
    "fig1, ax1=plt.subplots(1,1,figsize=(10,8))\n",
    "plt.xticks(rotation=40)\n",
    "lns4=ax1.plot(streamflow_analysis_obs_daily_mmday.index, streamflow_analysis_obs_daily_mmday,'k-', label='Streamflow- Observed',linewidth=2)\n",
    "lns5=ax1.plot(streamflow_analysis_mod_daily_mmday.index, streamflow_analysis_mod_daily_mmday,'r-', label='Streamflow- Modeled',linewidth=2)\n",
    "\n",
    "# Plot precipitation on top x-axis\n",
    "ax2=ax1.twinx()\n",
    "lns3=ax2.plot(precip_analysis_mod_daily.index, precip_analysis_mod_daily,'m-', label='Precipitation- Liv 2013 CIG, BC',linewidth=2)\n",
    "lns2=ax2.plot(precip_analysis_liv2016_met_daily.index, precip_analysis_liv2016_met_daily.mean(axis=1),'c-', label='Precipitation- Liv 2016',linewidth=2)\n",
    "lns1=ax2.plot(precip_analysis_liv2013_met_daily.index, precip_analysis_liv2013_met_daily.mean(axis=1),'b-', label='Precipitation- Liv 2013',linewidth=2)\n",
    "\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.xlim(graph_start_date, graph_end_date) # Set date range of interest\n",
    "ax1.set_xlabel('Date',fontsize=16)\n",
    "ax1.set_ylabel('Streamflow (mm/day)',fontsize=16) \n",
    "ax2.set_ylabel('Precipitation (mm/day)',fontsize=16)\n",
    "plt.title(str(loc_name)+': Precipitation and Streamflow\\n('+str(graph_start_date)+' thru '+str(graph_end_date)+')',fontsize=20)\n",
    "\n",
    "#lns=lns1+lns2 # Use if DO NOT HAVE modeled streamflow and precip\n",
    "lns=lns1+lns2+lns3+lns4+lns5 # Use if HAVE modeled streamflow and precip\n",
    "labs = [l.get_label() for l in lns]\n",
    "by_label = OrderedDict(zip(labs, lns))\n",
    "plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(0.8, -0.2), ncol=2)\n",
    "\n",
    "#ax1.legend(lns, labs, loc='best', fontsize=14)\n",
    "ax1.tick_params(labelsize=14)\n",
    "ax1.grid(which='both')\n",
    "ax2.tick_params(labelsize=14)\n",
    "ax2.grid(which='both')\n",
    "\n",
    "plt.savefig('hyetograph_hydrograph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% Comparison with SNOTEL data\n",
    "\n",
    "print('User to select and input a date range that overlaps between SNOTEL data and Livneh data (1915-2013)')\n",
    "print('SNOTEL observation start date:',SNOTEL_obs_start_date.date())\n",
    "print('User selected start date for analysis:',start_date)\n",
    "print('SNOTEL observation end date:',SNOTEL_obs_end_date.date())\n",
    "print('User selected end date for analysis:',end_date)\n",
    "\n",
    "# INPUT data range of comparison between Livneh and SNOTEL data\n",
    "comp_SNOTEL_start_date=SNOTEL_obs_start_date.date()\n",
    "comp_SNOTEL_end_date=end_date\n",
    "#comp_SNOTEL_start_date=datetime.date(2009,10,1)\n",
    "#comp_SNOTEL_end_date=datetime.date(2010,9,30)\n",
    "\n",
    "# Find climate station, within the range sleected for analysis, that is closest in elevation to the SNOTEL site.\n",
    "comp_SNOTEL_liv_sta_elev=int(analysis_stations_info.ix[(analysis_stations_info.elevation-SNOTEL_station_elev).abs().argsort()[0]].elevation) \n",
    "comp_SNOTEL_liv_sta_ind=analysis_stations_info.ix[(analysis_stations_info.elevation-SNOTEL_station_elev).abs().argsort()[0]].station\n",
    "\n",
    "# Temperature- Extract Livneh data for station with nearest elevation to SNOTEL site and make computations\n",
    "temp_min_comp_SNOTEL_liv2013_nearest_elev=temp_min_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, comp_SNOTEL_liv_sta_ind]\n",
    "temp_max_comp_SNOTEL_liv2013_nearest_elev=temp_max_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, comp_SNOTEL_liv_sta_ind]\n",
    "temp_avg_comp_SNOTEL_liv2013_nearest_elev=temp_avg_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, comp_SNOTEL_liv_sta_ind]\n",
    "\n",
    "meanmonth_temp_min_comp_SNOTEL_liv2013_nearest_elev=temp_min_comp_SNOTEL_liv2013_nearest_elev.groupby(temp_min_comp_SNOTEL_liv2013_nearest_elev.index.month).mean()\n",
    "meanmonth_temp_max_comp_SNOTEL_liv2013_nearest_elev=temp_max_comp_SNOTEL_liv2013_nearest_elev.groupby(temp_max_comp_SNOTEL_liv2013_nearest_elev.index.month).mean()\n",
    "meanmonth_temp_avg_comp_SNOTEL_liv2013_nearest_elev=temp_avg_comp_SNOTEL_liv2013_nearest_elev.groupby(temp_avg_comp_SNOTEL_liv2013_nearest_elev.index.month).mean()\n",
    "\n",
    "# Temperature- Extract Livneh data for station with max elevation to SNOTEL site and make computations\n",
    "temp_min_comp_SNOTEL_liv2013_max_elev=temp_min_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, analysis_elev_max_station]\n",
    "temp_max_comp_SNOTEL_liv2013_max_elev=temp_max_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, analysis_elev_max_station]\n",
    "temp_avg_comp_SNOTEL_liv2013_max_elev=temp_avg_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, analysis_elev_max_station]\n",
    "\n",
    "meanmonth_temp_min_comp_SNOTEL_liv2013_max_elev=temp_min_comp_SNOTEL_liv2013_max_elev.groupby(temp_min_comp_SNOTEL_liv2013_max_elev.index.month).mean()\n",
    "meanmonth_temp_max_comp_SNOTEL_liv2013_max_elev=temp_max_comp_SNOTEL_liv2013_max_elev.groupby(temp_max_comp_SNOTEL_liv2013_max_elev.index.month).mean()\n",
    "meanmonth_temp_avg_comp_SNOTEL_liv2013_max_elev=temp_avg_comp_SNOTEL_liv2013_max_elev.groupby(temp_avg_comp_SNOTEL_liv2013_max_elev.index.month).mean()\n",
    "\n",
    "# Temperature- Extract Livneh data for station with min elevation to SNOTEL site and make computations\n",
    "temp_min_comp_SNOTEL_liv2013_min_elev=temp_min_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, analysis_elev_min_station]\n",
    "temp_max_comp_SNOTEL_liv2013_min_elev=temp_max_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, analysis_elev_min_station]\n",
    "temp_avg_comp_SNOTEL_liv2013_min_elev=temp_avg_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, analysis_elev_min_station]\n",
    "\n",
    "meanmonth_temp_min_comp_SNOTEL_liv2013_min_elev=temp_min_comp_SNOTEL_liv2013_min_elev.groupby(temp_min_comp_SNOTEL_liv2013_min_elev.index.month).mean()\n",
    "meanmonth_temp_max_comp_SNOTEL_liv2013_min_elev=temp_max_comp_SNOTEL_liv2013_min_elev.groupby(temp_max_comp_SNOTEL_liv2013_min_elev.index.month).mean()\n",
    "meanmonth_temp_avg_comp_SNOTEL_liv2013_min_elev=temp_avg_comp_SNOTEL_liv2013_min_elev.groupby(temp_avg_comp_SNOTEL_liv2013_min_elev.index.month).mean()\n",
    "\n",
    "# Temperature- Extract appropriate SNOTEL data and make computations                                  \n",
    "temp_min_comp_SNOTEL_obs=SNOTEL_obs_daily.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, 'Tmin_C']\n",
    "temp_max_comp_SNOTEL_obs=SNOTEL_obs_daily.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, 'Tmax_C']\n",
    "temp_avg_comp_SNOTEL_obs=SNOTEL_obs_daily.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, 'Tavg_C']\n",
    "\n",
    "meanmonth_temp_min_comp_SNOTEL_obs=temp_min_comp_SNOTEL_obs.groupby(temp_min_comp_SNOTEL_obs.index.month).mean()\n",
    "meanmonth_temp_max_comp_SNOTEL_obs=temp_max_comp_SNOTEL_obs.groupby(temp_max_comp_SNOTEL_obs.index.month).mean()\n",
    "meanmonth_temp_avg_comp_SNOTEL_obs=temp_avg_comp_SNOTEL_obs.groupby(temp_avg_comp_SNOTEL_obs.index.month).mean()\n",
    "\n",
    "# Precipitation- Compare both Livneh datasets and modeled datasets (if applicable). Only compare for all elevations and nearest elevation to SNOTEL station\n",
    "# All elevations\n",
    "precip_comp_SNOTEL_liv2013_all_elev=precip_liv2013_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, range(0,n_stations)]\n",
    "precip_comp_SNOTEL_liv2016_all_elev=precip_liv2016_met_daily_df.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, range(0,n_stations)]\n",
    "\n",
    "permonth_precip_comp_SNOTEL_liv2013_all_elev=precip_comp_SNOTEL_liv2013_all_elev.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "permonth_precip_comp_SNOTEL_liv2016_all_elev=precip_comp_SNOTEL_liv2016_all_elev.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "\n",
    "meanpermonth_precip_comp_SNOTEL_liv2013_all_elev=permonth_precip_comp_SNOTEL_liv2013_all_elev.mean(axis=1)\n",
    "meanpermonth_precip_comp_SNOTEL_liv2016_all_elev=permonth_precip_comp_SNOTEL_liv2016_all_elev.mean(axis=1)\n",
    "\n",
    "month_precip_comp_SNOTEL_liv2013_all_elev=meanpermonth_precip_comp_SNOTEL_liv2013_all_elev.groupby(meanpermonth_precip_comp_SNOTEL_liv2013_all_elev.index.month).mean()\n",
    "month_precip_comp_SNOTEL_liv2016_all_elev=meanpermonth_precip_comp_SNOTEL_liv2016_all_elev.groupby(meanpermonth_precip_comp_SNOTEL_liv2016_all_elev.index.month).mean()\n",
    "\n",
    "\n",
    "if 'precip_mod_daily' in locals():\n",
    "    precip_comp_SNOTEL_mod=precip_mod_daily.precip_mm[comp_SNOTEL_start_date:comp_SNOTEL_end_date]\n",
    "    permonth_precip_comp_SNOTEL_mod=precip_comp_SNOTEL_mod.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "    month_precip_comp_SNOTEL_mod=permonth_precip_comp_SNOTEL_mod.groupby(permonth_precip_comp_SNOTEL_mod.index.month).mean()\n",
    "\n",
    "# SNOTEL data and nearest Livneh station\n",
    "precip_comp_SNOTEL_liv2013_nearest_elev=permonth_precip_comp_SNOTEL_liv2013_all_elev.loc[:, comp_SNOTEL_liv_sta_ind]\n",
    "precip_comp_SNOTEL_liv2016_nearest_elev=permonth_precip_comp_SNOTEL_liv2016_all_elev.loc[:, comp_SNOTEL_liv_sta_ind]\n",
    "\n",
    "month_precip_comp_SNOTEL_liv2013_nearest_elev=precip_comp_SNOTEL_liv2013_nearest_elev.groupby(meanpermonth_precip_comp_SNOTEL_liv2013_all_elev.index.month).mean()\n",
    "month_precip_comp_SNOTEL_liv2016_nearest_elev=precip_comp_SNOTEL_liv2016_nearest_elev.groupby(meanpermonth_precip_comp_SNOTEL_liv2016_all_elev.index.month).mean()\n",
    "\n",
    "precip_comp_SNOTEL_obs=SNOTEL_obs_daily.loc[comp_SNOTEL_start_date:comp_SNOTEL_end_date, 'Precip_mm']\n",
    "permonth_precip_comp_SNOTEL_obs=precip_comp_SNOTEL_obs.groupby(pandas.TimeGrouper(\"M\")).sum()\n",
    "month_precip_comp_SNOTEL_obs=permonth_precip_comp_SNOTEL_obs.groupby(permonth_precip_comp_SNOTEL_obs.index.month).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Plot X: Monthly temperature comparison of Livneh and SNOTEL data\n",
    "fig, ax=plt.subplots(1,1,figsize=(10, 6))\n",
    "\n",
    "# Tmax\n",
    "plt.plot(wy_index, meanmonth_temp_max_comp_SNOTEL_liv2013_min_elev[wy_numbers],'r^:',linewidth=1, label='Liv Tmax- Min Elev='+str(analysis_elev_min)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_max_comp_SNOTEL_liv2013_nearest_elev[wy_numbers],'ro--',linewidth=1, label='Liv Tmax- Elev='+str(comp_SNOTEL_liv_sta_elev)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_max_comp_SNOTEL_obs[wy_numbers],'rs-',linewidth=1, label='SNOTEL Tmax- Elev='+str(SNOTEL_station_elev)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_max_comp_SNOTEL_liv2013_max_elev[wy_numbers],'r*:',linewidth=1, label='Liv Tmax- Max Elev='+str(analysis_elev_max)+'m')\n",
    "\n",
    "#Tmin\n",
    "plt.plot(wy_index, meanmonth_temp_min_comp_SNOTEL_liv2013_min_elev[wy_numbers],'b^:',linewidth=1, label='Liv Tmin- Min Elev='+str(analysis_elev_min)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_min_comp_SNOTEL_liv2013_nearest_elev[wy_numbers],'bo--',linewidth=1, label='Liv Tmin- Elev='+str(comp_SNOTEL_liv_sta_elev)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_min_comp_SNOTEL_obs[wy_numbers],'bs-',linewidth=1, label='SNOTEL Tmin- Elev='+str(SNOTEL_station_elev)+'m')\n",
    "plt.plot(wy_index, meanmonth_temp_min_comp_SNOTEL_liv2013_max_elev[wy_numbers],'b*:',linewidth=1, label='Liv Tmin- Max Elev='+str(analysis_elev_max)+'m')\n",
    "\n",
    "## Tavg\n",
    "#plt.plot(wy_index, meanmonth_temp_avg_analysis_liv2013_met_daily[wy_numbers],'go-',linewidth=1, label='Liv 2013 Met- Tavg')\n",
    "#plt.plot(wy_index, meanmonth_temp_avg_analysis_liv2016_met_daily[wy_numbers],'g*-',linewidth=1, label='Liv 2016 Met- Tavg')\n",
    "\n",
    "# Highlight 0 line \n",
    "plt.plot([1, 12],[0, 0], 'k-',linewidth=1)\n",
    "\n",
    "plt.xlabel ('Month',fontsize=14)\n",
    "plt.ylabel('Temperature (deg C)',fontsize=14)\n",
    "plt.title(str(loc_name)+'\\nAverage Monthly Max and Min Temperature- Livneh vs SNOTEL\\n Dates: '+str(comp_SNOTEL_start_date)+' thru '+str(comp_SNOTEL_end_date)+'; Elevation: '+str(analysis_elev_min)+'m -'+str(analysis_elev_max)+'m', fontsize=16)\n",
    "plt.legend(bbox_to_anchor=(0.9, -0.15), ncol=2)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(1,12);\n",
    "plt.xticks(wy_index, month_strings);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot X: Monthly precipitation comparison of Livneh and SNOTEL data\n",
    "fig, ax=plt.subplots(1,1,figsize=(10, 6))\n",
    "\n",
    "plt.plot(wy_index, month_precip_comp_SNOTEL_liv2013_all_elev[wy_numbers],'bo--',linewidth=1, label='Liv 2013 Met- All Elev')\n",
    "plt.plot(wy_index, month_precip_comp_SNOTEL_liv2016_all_elev[wy_numbers],'co--',linewidth=1, label='Liv 2016 Met- All Elev')\n",
    "plt.plot(wy_index, month_precip_analysis_mod_daily[wy_numbers],'mo--',linewidth=1, label='Liv 2013 CIG, BC- All Elev')\n",
    "\n",
    "plt.plot(wy_index, month_precip_comp_SNOTEL_liv2013_nearest_elev[wy_numbers],'bs-',linewidth=1, label='Liv 2013 Met- Elev='+str(comp_SNOTEL_liv_sta_elev)+'m')\n",
    "plt.plot(wy_index,month_precip_comp_SNOTEL_liv2016_nearest_elev[wy_numbers],'cs-',linewidth=1, label='Liv 2016 Met- Elev='+str(comp_SNOTEL_liv_sta_elev)+'m')\n",
    "plt.plot(wy_index, month_precip_comp_SNOTEL_obs[wy_numbers],'rs-',linewidth=1, label='SNOTEL- Elev='+str(SNOTEL_station_elev)+'m')\n",
    "\n",
    "## Tavg\n",
    "#plt.plot(wy_index, meanmonth_temp_avg_analysis_liv2013_met_daily[wy_numbers],'go-',linewidth=1, label='Liv 2013 Met- Tavg')\n",
    "#plt.plot(wy_index, meanmonth_temp_avg_analysis_liv2016_met_daily[wy_numbers],'g*-',linewidth=1, label='Liv 2016 Met- Tavg')\n",
    "\n",
    "# Highlight 0 line \n",
    "plt.plot([1, 12],[0, 0], 'k-',linewidth=1)\n",
    "\n",
    "plt.xlabel ('Month',fontsize=14)\n",
    "plt.ylabel('Monthly Precipitation (mm)',fontsize=14)\n",
    "plt.title(str(loc_name)+'\\nMonthly Precipitation- Livneh vs SNOTEL\\n Dates: '+str(comp_SNOTEL_start_date)+' thru '+str(comp_SNOTEL_end_date)+'; Elevation: '+str(analysis_elev_min)+'m -'+str(analysis_elev_max)+'m', fontsize=16)\n",
    "plt.legend(bbox_to_anchor=(0.9, -0.15), ncol=2)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(1,12);\n",
    "plt.xticks(wy_index, month_strings);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 3b: Hyetograph versus Observed Runoff- Monthly average\n",
    "fig, ax3=plt.subplots(1,1,figsize=(5,5))\n",
    "plt.xticks(rotation=40)\n",
    "mod_plot=permonth_streamflow_analysis_mod_daily_mmday[graph_start_date:graph_end_date]\n",
    "obs_plot=permonth_streamflow_analysis_obs_daily_mmday[graph_start_date:graph_end_date]\n",
    "max_q=np.max(np.concatenate([mod_plot, obs_plot]))\n",
    "plt.plot(mod_plot, obs_plot,'ro',linewidth=2)\n",
    "plt.plot([0, max_q+20], [0, max_q+20],'k-',linewidth=1)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Modeled Streamflow (mm/month)',fontsize=16)\n",
    "plt.ylabel('Observed Streamflow (mm/month)',fontsize=16)\n",
    "plt.title(str(loc_name)+':\\n Modeled vs. Observed Streamflow (Monthly) \\n('+str(graph_start_date)+' thru '+str(graph_end_date)+')',fontsize=20)\n",
    "ax3.tick_params(labelsize=14)\n",
    "ax3.grid(which='both')\n",
    "plt.savefig('hyetograph_hydrograph_compare.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 4: Cumulative Precipitation and Runoff\n",
    "# INPUT start and end date of interest in single quotes- can comment out if want same date range as Plot 3a/3b\n",
    "#graph_start_date='10-1-1998'\n",
    "#graph_end_date='9-30-1999'\n",
    "\n",
    "cum_precip_liv2013_met_daily=precip_analysis_liv2013_met_daily[graph_start_date:graph_end_date].mean(axis=1).cumsum(axis=0) # cumulative sum of precipitation that is averaged over stations (horizontally across columns)\n",
    "cum_precip_liv2016_met_daily=precip_analysis_liv2016_met_daily[graph_start_date:graph_end_date].mean(axis=1).cumsum(axis=0) # cumulative sum of precipitation that is averaged over stations (horizontally across columns)\n",
    "cum_precip_mod_daily=precip_mod_daily.precip_mm[graph_start_date:graph_end_date].cumsum(axis=0)\n",
    "cum_streamflow_obs_mm=streamflow_analysis_obs_daily_mmday[graph_start_date:graph_end_date].cumsum(axis=0) # cumulative sum of observed streamflow\n",
    "cum_streamflow_mod_mm=streamflow_analysis_mod_daily_mmday[graph_start_date:graph_end_date].cumsum(axis=0) # cumulative sum of modeled streamflow\n",
    "\n",
    "fig1, ax1=plt.subplots(1,1,figsize=(10,8))\n",
    "plt.xticks(rotation=40)\n",
    "lns4=ax1.plot(streamflow_analysis_obs_daily_mmday[graph_start_date:graph_end_date].index, cum_streamflow_obs_mm,'k-', label='Streamflow- Observed',linewidth=2)\n",
    "lns5=ax1.plot(streamflow_analysis_mod_daily_mmday[graph_start_date:graph_end_date].index, cum_streamflow_mod_mm,'r-', label='Streamflow- Modeled',linewidth=2)\n",
    "lns1=ax1.plot(precip_analysis_liv2013_met_daily[graph_start_date:graph_end_date].index, cum_precip_liv2013_met_daily,'b-', label='Precipitation- Liv 2013',linewidth=2)\n",
    "lns2=ax1.plot(precip_analysis_liv2016_met_daily[graph_start_date:graph_end_date].index, cum_precip_liv2016_met_daily,'g-', label='Precipitation- Liv 2016',linewidth=2)\n",
    "lns3=ax1.plot(precip_mod_daily[graph_start_date:graph_end_date].index, cum_precip_mod_daily,'m-', label='Precipitation- Liv 2013 CIG, BC',linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('Date',fontsize=16)\n",
    "ax1.set_ylabel('Streamflow and Precipitation (mm)',fontsize=16) \n",
    "plt.title(str(loc_name)+': Cumulative Precipitation and Streamflow\\n('+str(graph_start_date)+' thru '+str(graph_end_date)+')',fontsize=20)\n",
    "\n",
    "lns=lns1+lns2+lns3+lns4+lns5\n",
    "#lns=lns1+lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "by_label = OrderedDict(zip(labs, lns))\n",
    "plt.legend(by_label.values(), by_label.keys(), loc='best')\n",
    "#plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(0.8, -0.2), ncol=2)\n",
    "\n",
    "RR_Liv2013=round(cum_streamflow_obs_mm[-1]/cum_precip_liv2013_met_daily[-1],2)\n",
    "RR_Liv2016=round(cum_streamflow_obs_mm[-1]/cum_precip_liv2016_met_daily[-1],2)\n",
    "RR_Liv2013CIGBC=round(cum_streamflow_obs_mm[-1]/cum_precip_mod_daily[-1],2)\n",
    "plt.text(1.2, 0.50,'RR, Liv 2013='+str(RR_Liv2013), horizontalalignment='right', verticalalignment='bottom',  transform = ax.transAxes)\n",
    "plt.text(1.2, 0.55,'RR, Liv 2016='+str(RR_Liv2016), horizontalalignment='right', verticalalignment='bottom',  transform = ax.transAxes)\n",
    "plt.text(1.2, 0.6,'RR, Liv 2013, CIG BC='+str(RR_Liv2013CIGBC), horizontalalignment='right', verticalalignment='bottom',  transform = ax.transAxes)\n",
    "\n",
    "ax1.tick_params(labelsize=14)\n",
    "ax1.grid(which='both')\n",
    "plt.savefig('cum_precip_streamflow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 5: Climate Index- by month\n",
    "fig1, ax1=plt.subplots(1,1,figsize=(8,8))\n",
    "plt.subplot(3,1,1)\n",
    "plt.xticks(rotation=0)\n",
    "plt.plot(anom_month_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_month_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_month_temp_avg_analysis_liv2013_met_daily.index, anom_month_temp_avg_analysis_liv2013_met_daily,'k-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_month_temp_avg_analysis_liv2016_met_daily.index, anom_month_temp_avg_analysis_liv2016_met_daily,'r-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_month_temp_avg_analysis_liv2013_met_daily.index[0],anom_month_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+': Temperature Anomalies',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('T anomaly, deg C')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.xticks(rotation=0)\n",
    "plt.plot(anom_month_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_month_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_month_precip_analysis_liv2013_met_daily.index, anom_month_precip_analysis_liv2013_met_daily,'b-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_month_precip_analysis_liv2016_met_daily.index, anom_month_precip_analysis_liv2016_met_daily,'g-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_month_temp_avg_analysis_liv2013_met_daily.index[0],anom_month_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+': Precipitation Anomalies',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('P anomaly, m')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.plot(anom_month_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_month_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_month_precip_analysis_liv2013_met_daily.index, CI_liv2013_monthly,'k-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_month_precip_analysis_liv2016_met_daily.index, CI_liv2016_monthly,'m-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_month_temp_avg_analysis_liv2013_met_daily.index[0],anom_month_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+': Monthly Climate Index',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Monthly Climate Index')\n",
    "\n",
    "fig2, ax2=plt.subplots(1,1)\n",
    "plt.plot(anom_month_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_month_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_month_precip_analysis_liv2013_met_daily.index, CI_liv2013_monthly.cumsum(),'k-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_month_precip_analysis_liv2016_met_daily.index, CI_liv2016_monthly.cumsum(),'m-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_month_temp_avg_analysis_liv2013_met_daily.index[0],anom_month_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+': Monthly Climate Index,\\nCumulative Departure Fom Mean',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Monthly Climate Index')\n",
    "plt.savefig('climate_index_monthly.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%% Plot 6: Climate Index- by water year\n",
    "fig1, ax1=plt.subplots(1,1,figsize=(8,8))\n",
    "plt.subplot(3,1,1)\n",
    "plt.xticks(rotation=0)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_wyear_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_wyear_temp_avg_analysis_liv2013_met_daily.index, anom_wyear_temp_avg_analysis_liv2013_met_daily,'k-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_wyear_temp_avg_analysis_liv2016_met_daily.index, anom_wyear_temp_avg_analysis_liv2016_met_daily,'r-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_wyear_temp_avg_analysis_liv2013_met_daily.index[0],anom_wyear_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+':Temperature Anomalies',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('T anomaly, deg C')\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.xticks(rotation=0)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_wyear_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2013_met_daily.index, anom_wyear_precip_analysis_liv2013_met_daily,'b-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2016_met_daily.index, anom_wyear_precip_analysis_liv2016_met_daily,'g-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_wyear_temp_avg_analysis_liv2013_met_daily.index[0],anom_wyear_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+':Precipitation Anomalies',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('P anomaly, m')\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_wyear_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2013_met_daily.index, CI_liv2013_wy,'k-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2016_met_daily.index, CI_liv2016_wy,'m-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_wyear_temp_avg_analysis_liv2013_met_daily.index[0],anom_wyear_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+':Annual (Water Year) Climate Index',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Annual Climate Index')\n",
    "\n",
    "fig2, ax2=plt.subplots(1,1)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2016_met_daily.index, np.zeros(len(anom_wyear_precip_analysis_liv2016_met_daily)),'k-', linewidth=1)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2013_met_daily.index, CI_liv2013_wy.cumsum(),'k-', label='Liv 2013',linewidth=2)\n",
    "plt.plot(anom_wyear_precip_analysis_liv2016_met_daily.index, CI_liv2016_wy.cumsum(),'m-', label='Liv 2016',linewidth=2)\n",
    "plt.tick_params(labelsize=10)\n",
    "plt.grid(which='both')\n",
    "plt.xlim(anom_wyear_temp_avg_analysis_liv2013_met_daily.index[0],anom_wyear_temp_avg_analysis_liv2013_met_daily.index[-1])\n",
    "plt.title(str(loc_name)+': Annual (Water Year) Climate Index,\\nCumulative Departure Fom Mean',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Annual Climate Index')\n",
    "plt.savefig('climate_index_annual_wy.png')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
